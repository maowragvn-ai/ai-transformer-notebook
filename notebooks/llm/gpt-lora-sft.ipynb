{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11280244,"sourceType":"datasetVersion","datasetId":7052350}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers datasets peft torch pandas numpy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\nfrom datasets import Dataset, ClassLabel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:43.138625Z","iopub.execute_input":"2025-04-05T02:21:43.138923Z","iopub.status.idle":"2025-04-05T02:21:45.611153Z","shell.execute_reply.started":"2025-04-05T02:21:43.138892Z","shell.execute_reply":"2025-04-05T02:21:45.610251Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"input_path = \"/kaggle/input/qa-tradelane/qa_trade_lane_dataset.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:48.800029Z","iopub.execute_input":"2025-04-05T02:21:48.800297Z","iopub.status.idle":"2025-04-05T02:21:48.803879Z","shell.execute_reply.started":"2025-04-05T02:21:48.800275Z","shell.execute_reply":"2025-04-05T02:21:48.802991Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"qa_df = pd.read_csv(input_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:50.018301Z","iopub.execute_input":"2025-04-05T02:21:50.018602Z","iopub.status.idle":"2025-04-05T02:21:50.101168Z","shell.execute_reply.started":"2025-04-05T02:21:50.018575Z","shell.execute_reply":"2025-04-05T02:21:50.100455Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"qa_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:51.204014Z","iopub.execute_input":"2025-04-05T02:21:51.204273Z","iopub.status.idle":"2025-04-05T02:21:51.224728Z","shell.execute_reply.started":"2025-04-05T02:21:51.204252Z","shell.execute_reply":"2025-04-05T02:21:51.224006Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            question  answer\n0  Trade Lane Type: exporting. From Region: south...     188\n1  Trade Lane Type: exporting. From Region: south...     188\n2  Trade Lane Type: exporting. From Region: south...     188\n3  Trade Lane Type: exporting. From Region: south...     188\n4  Trade Lane Type: exporting. From Region: south...     188","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trade Lane Type: exporting. From Region: south...</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Trade Lane Type: exporting. From Region: south...</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Trade Lane Type: exporting. From Region: south...</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trade Lane Type: exporting. From Region: south...</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trade Lane Type: exporting. From Region: south...</td>\n      <td>188</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Load your dataset\ndataset = Dataset.from_pandas(qa_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:52.495940Z","iopub.execute_input":"2025-04-05T02:21:52.496216Z","iopub.status.idle":"2025-04-05T02:21:52.529357Z","shell.execute_reply.started":"2025-04-05T02:21:52.496194Z","shell.execute_reply":"2025-04-05T02:21:52.528730Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"set_labels = set(dataset['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:53.615905Z","iopub.execute_input":"2025-04-05T02:21:53.616209Z","iopub.status.idle":"2025-04-05T02:21:53.627572Z","shell.execute_reply.started":"2025-04-05T02:21:53.616183Z","shell.execute_reply":"2025-04-05T02:21:53.626848Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"unique_labels = sorted(set_labels)\nlabel_map = {label: idx for idx, label in enumerate(unique_labels)}\nprint(label_map)\nnum_classes = len(unique_labels)\nprint(num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:54.450117Z","iopub.execute_input":"2025-04-05T02:21:54.450369Z","iopub.status.idle":"2025-04-05T02:21:54.455500Z","shell.execute_reply.started":"2025-04-05T02:21:54.450348Z","shell.execute_reply":"2025-04-05T02:21:54.454839Z"}},"outputs":[{"name":"stdout","text":"{188: 0, 191: 1, 196: 2, 197: 3, 198: 4, 199: 5, 205: 6, 416: 7, 582: 8, 849: 9}\n10\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"dataset = dataset.cast_column('answer', ClassLabel(num_classes=num_classes, names=list(unique_labels)))\n# N·∫øu c·∫ßn chia th√†nh train/test\ndataset = dataset.train_test_split(test_size=0.3, stratify_by_column='answer', seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:55.697632Z","iopub.execute_input":"2025-04-05T02:21:55.697961Z","iopub.status.idle":"2025-04-05T02:21:55.757507Z","shell.execute_reply.started":"2025-04-05T02:21:55.697932Z","shell.execute_reply":"2025-04-05T02:21:55.756693Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/13824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dcfe9685f284f748252f77662e3c22f"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token  # Set padding token\n\ndef preprocess_function(examples):\n    # Tokenize the texts\n    tokenized_inputs = tokenizer(\n        examples['question'],  # Assuming 'question' is your input text column\n        padding='max_length',\n        truncation=True,\n        max_length=128,\n    )\n\n    # Convert answers to integers if they're not already\n    labels = [label_map[int(a)] for a in examples[\"answer\"]]\n    result = tokenized_inputs.copy()\n    result[\"labels\"] = labels\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:21:57.282910Z","iopub.execute_input":"2025-04-05T02:21:57.283188Z","iopub.status.idle":"2025-04-05T02:22:09.582937Z","shell.execute_reply.started":"2025-04-05T02:21:57.283166Z","shell.execute_reply":"2025-04-05T02:22:09.582073Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61eb7d97b5774d739f3b58a83ee40be4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5171330c443c4a49b13666b9f9d506ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a01f0c147a44685bc128a16ba093459"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa1f03317fc543d98a9cee77f1e3160c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55b3a4370ddf4056b8ca79752a0581d6"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tokenized_datasets = {}\nfor split in ['train', 'test']:\n  tokenized_datasets[split] = dataset[split].map(\n      preprocess_function,\n      batched=True,\n      remove_columns=dataset[split].column_names\n  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:22:09.584158Z","iopub.execute_input":"2025-04-05T02:22:09.584731Z","iopub.status.idle":"2025-04-05T02:22:16.670559Z","shell.execute_reply.started":"2025-04-05T02:22:09.584696Z","shell.execute_reply":"2025-04-05T02:22:16.669547Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9676 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8af9c2abc224dca93b616b08b2e5687"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4148 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4bb8ae69a8455897a1d75a1cdedcff"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import GPT2ForSequenceClassification\nfrom peft import LoraConfig, get_peft_model\n\n# Load base model\nmodel = GPT2ForSequenceClassification.from_pretrained(\n    'gpt2',\n    num_labels=num_classes,\n    pad_token_id=tokenizer.eos_token_id\n)\n\n# Define LoRA config\nlora_config = LoraConfig(\n    r=8,  # Rank\n    lora_alpha=16,\n    target_modules=[\"c_attn\"],  # Targeting attention layers\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"  # Sequence classification\n)\n\n# Apply LoRA\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()  # Should show much fewer trainable params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:22:18.084003Z","iopub.execute_input":"2025-04-05T02:22:18.084440Z","iopub.status.idle":"2025-04-05T02:22:33.083367Z","shell.execute_reply.started":"2025-04-05T02:22:18.084399Z","shell.execute_reply":"2025-04-05T02:22:33.082439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"363cdeb66e8942ec8c50b4f52a55318f"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 302,592 || all params: 124,750,080 || trainable%: 0.2426\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    \n    # Calculate basic metrics\n    accuracy = accuracy_score(labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, predictions, average='weighted'\n    )\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:22:39.857643Z","iopub.execute_input":"2025-04-05T02:22:39.858278Z","iopub.status.idle":"2025-04-05T02:22:39.863084Z","shell.execute_reply.started":"2025-04-05T02:22:39.858244Z","shell.execute_reply":"2025-04-05T02:22:39.862214Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    report_to=\"none\",\n    metric_for_best_model=\"f1\",  # Use F1 score to select best model\n    greater_is_better=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],  # You should have a separate validation set\n    compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:22:41.955868Z","iopub.execute_input":"2025-04-05T02:22:41.956181Z","iopub.status.idle":"2025-04-05T02:22:43.535791Z","shell.execute_reply.started":"2025-04-05T02:22:41.956157Z","shell.execute_reply":"2025-04-05T02:22:43.534906Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T02:22:45.586666Z","iopub.execute_input":"2025-04-05T02:22:45.587013Z","iopub.status.idle":"2025-04-05T02:29:08.197449Z","shell.execute_reply.started":"2025-04-05T02:22:45.586984Z","shell.execute_reply":"2025-04-05T02:29:08.196833Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3630' max='3630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3630/3630 06:21, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.581900</td>\n      <td>1.478413</td>\n      <td>0.400916</td>\n      <td>0.229469</td>\n      <td>0.160734</td>\n      <td>0.400916</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.226300</td>\n      <td>0.634579</td>\n      <td>0.743491</td>\n      <td>0.656405</td>\n      <td>0.827016</td>\n      <td>0.743491</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.655000</td>\n      <td>0.523646</td>\n      <td>0.755545</td>\n      <td>0.670221</td>\n      <td>0.828859</td>\n      <td>0.755545</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3630, training_loss=1.2453733396924231, metrics={'train_runtime': 382.2838, 'train_samples_per_second': 75.933, 'train_steps_per_second': 9.496, 'total_flos': 1903113326297088.0, 'train_loss': 1.2453733396924231, 'epoch': 3.0})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Save the model\nmodel.save_pretrained(\"gpt2-lora-classification\")\n\n# To load later:\nfrom peft import PeftModel\nloaded_model = GPT2ForSequenceClassification.from_pretrained('gpt2-medium')\nloaded_model = PeftModel.from_pretrained(loaded_model, \"gpt2-lora-classification\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    outputs = model(**inputs)\n    logits = outputs.logits\n    return logits.argmax().item()\n\n# Example usage\nquestion = \"Trade Lane Type: exporting. From Region: south...\"\npredicted_class = predict(question)\nprint(f\"Predicted class: {predicted_class}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}